{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-04T21:15:15.934658Z",
     "start_time": "2025-10-04T21:14:49.356640Z"
    }
   },
   "source": [
    "from sklearn.metrics import classification_report, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "\n",
    "%store -r export_df\n",
    "df = export_df\n",
    "print(df)\n",
    "\n",
    "\n",
    "x = df.drop(columns=['activity'])\n",
    "y = df['activity']\n",
    "\n",
    "label_encoder = LabelEncoder() # Encode target\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler() # Normalize features\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.1, random_state=42, shuffle=False\n",
    ")\n",
    "# split_index = int(len(df) * 0.9)\n",
    "# x_train, x_test = x.iloc[:split_index], x.iloc[split_index:]\n",
    "# y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "forest_model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(label_encoder.classes_),\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.15,\n",
    "    gamma=1,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "neural_model = Sequential([\n",
    "    Input(shape=(x_train_scaled.shape[1],)),  # explicitly define input\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # multi-class\n",
    "])\n",
    "\n",
    "neural_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "neural_model.summary()\n",
    "\n",
    "forest_model.fit(x_train, y_train)\n",
    "xgb_model.fit(x_train, y_train_encoded)\n",
    "neural_model.fit(\n",
    "    x_train_scaled, y_train_encoded,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "predictions_rf = forest_model.predict(x_test)\n",
    "\n",
    "proba = xgb_model.predict_proba(x_test)\n",
    "predictions_xgb = np.argmax(proba, axis=1)\n",
    "predictions_xgb_decoded = label_encoder.inverse_transform(predictions_xgb)\n",
    "\n",
    "y_pred_probs = neural_model.predict(x_test_scaled)\n",
    "predictions_neural = np.argmax(y_pred_probs, axis=1)\n",
    "predictions_neural_decoded = label_encoder.inverse_transform(predictions_neural)\n",
    "\n",
    "acc_rf = classification_report(y_test, predictions_rf)\n",
    "acc_xgb = classification_report(y_test, predictions_xgb_decoded)\n",
    "acc_neural = classification_report(y_test, predictions_neural_decoded)\n",
    "\n",
    "#\n",
    "# print(acc_rf)\n",
    "# print(acc_xgb)\n",
    "# print(acc_neural)\n",
    "# print(df['activity'].value_counts())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          open       high        low      close     volume  \\\n",
      "timestamp                                                                    \n",
      "2025-08-18 17:15:00  116243.96  116688.00  116243.95  116516.11  274.31192   \n",
      "2025-08-18 17:30:00  116516.11  116800.00  116516.10  116532.67  235.18710   \n",
      "2025-08-18 17:45:00  116532.68  116625.10  116428.98  116428.99  102.21270   \n",
      "2025-08-18 18:00:00  116428.98  116437.44  116300.78  116360.97   74.19460   \n",
      "2025-08-18 18:15:00  116360.97  116458.35  116238.71  116360.98   65.74689   \n",
      "...                        ...        ...        ...        ...        ...   \n",
      "2025-10-04 19:45:00  121887.87  121959.25  121881.00  121959.25   40.40788   \n",
      "2025-10-04 20:00:00  121959.25  122079.65  121891.49  121939.96  103.29350   \n",
      "2025-10-04 20:15:00  121939.97  122057.28  121939.96  122057.28   32.70135   \n",
      "2025-10-04 20:30:00  122057.28  122057.28  121986.29  122029.48   28.84323   \n",
      "2025-10-04 20:45:00  122029.48  122061.83  121892.89  121892.89   46.40779   \n",
      "\n",
      "                           dxy      rsi_6     rsi_12        macd  macd_signal  \\\n",
      "timestamp                                                                       \n",
      "2025-08-18 17:15:00  98.169998  78.500628  69.316542  258.064544   166.334272   \n",
      "2025-08-18 17:30:00  98.169998  78.874483  69.563374  285.241314   190.115680   \n",
      "2025-08-18 17:45:00  98.169998  69.760605  65.940337  295.012273   211.094999   \n",
      "2025-08-18 18:00:00  98.169998  63.943757  63.570713  293.879522   227.651903   \n",
      "2025-08-18 18:15:00  98.169998  63.944287  63.570923  289.643783   240.050279   \n",
      "...                        ...        ...        ...         ...          ...   \n",
      "2025-10-04 19:45:00  97.720001  68.165378  55.165783  -65.970239  -102.025042   \n",
      "2025-10-04 20:00:00  97.720001  65.067791  54.059433  -50.938739   -91.807781   \n",
      "2025-10-04 20:15:00  97.720001  73.767736  59.454465  -29.222563   -79.290738   \n",
      "2025-10-04 20:30:00  97.720001  68.889136  57.702781  -14.093109   -66.251212   \n",
      "2025-10-04 20:45:00  97.720001  49.563108  49.833184  -12.975011   -55.595972   \n",
      "\n",
      "                     ...  trends with sma  price change  activity  \\\n",
      "timestamp            ...                                            \n",
      "2025-08-18 17:15:00  ...         0.009863  2.338461e-03      Sell   \n",
      "2025-08-18 17:30:00  ...         0.009857  1.421162e-04      Sell   \n",
      "2025-08-18 17:45:00  ...         0.008809 -8.901036e-04      Sell   \n",
      "2025-08-18 18:00:00  ...         0.008011 -5.843895e-04      Sell   \n",
      "2025-08-18 18:15:00  ...         0.007893  8.593947e-08      Sell   \n",
      "...                  ...              ...           ...       ...   \n",
      "2025-10-04 19:45:00  ...        -0.000765  5.854488e-04       Buy   \n",
      "2025-10-04 20:00:00  ...        -0.000862 -1.581801e-04      Sell   \n",
      "2025-10-04 20:15:00  ...         0.000143  9.616503e-04      Sell   \n",
      "2025-10-04 20:30:00  ...        -0.000014 -2.277879e-04      Sell   \n",
      "2025-10-04 20:45:00  ...        -0.001045 -1.119947e-03      Sell   \n",
      "\n",
      "                     bollinger_hband  bollinger_lband  bollinger_mavg  \\\n",
      "timestamp                                                               \n",
      "2025-08-18 17:15:00    116496.073938    114856.795062     115676.4345   \n",
      "2025-08-18 17:30:00    116619.773993    114853.249007     115736.5115   \n",
      "2025-08-18 17:45:00    116708.470434    114855.452566     115781.9615   \n",
      "2025-08-18 18:00:00    116775.224462    114872.254538     115823.7395   \n",
      "2025-08-18 18:15:00    116834.905611    114882.848389     115858.8770   \n",
      "...                              ...              ...             ...   \n",
      "2025-10-04 19:45:00    121958.569851    121594.640149     121776.6050   \n",
      "2025-10-04 20:00:00    121966.227475    121590.707525     121778.4675   \n",
      "2025-10-04 20:15:00    122016.803497    121572.465503     121794.6345   \n",
      "2025-10-04 20:30:00    122042.675702    121560.106298     121801.3910   \n",
      "2025-10-04 20:45:00    122050.947424    121561.992576     121806.4700   \n",
      "\n",
      "                    bollinger_bandwidth         atr  volume_change  \\\n",
      "timestamp                                                            \n",
      "2025-08-18 17:15:00            1.417124  345.226910       1.705803   \n",
      "2025-08-18 17:30:00            1.526333  340.846416      -0.142629   \n",
      "2025-08-18 17:45:00            1.600437  330.508815      -0.565398   \n",
      "2025-08-18 18:00:00            1.642988  316.662471      -0.274116   \n",
      "2025-08-18 18:15:00            1.684858  309.732295      -0.113859   \n",
      "...                                 ...         ...            ...   \n",
      "2025-10-04 19:45:00            0.298850  156.808460      -0.281025   \n",
      "2025-10-04 20:00:00            0.308363  159.047856       1.556271   \n",
      "2025-10-04 20:15:00            0.364826  156.067295      -0.683413   \n",
      "2025-10-04 20:30:00            0.396194  149.990345      -0.117980   \n",
      "2025-10-04 20:45:00            0.401419  151.343892       0.608966   \n",
      "\n",
      "                     volume_sma_10  \n",
      "timestamp                           \n",
      "2025-08-18 17:15:00     166.851868  \n",
      "2025-08-18 17:30:00     180.831528  \n",
      "2025-08-18 17:45:00     180.755104  \n",
      "2025-08-18 18:00:00     153.212626  \n",
      "2025-08-18 18:15:00     134.962513  \n",
      "...                            ...  \n",
      "2025-10-04 19:45:00      66.467125  \n",
      "2025-10-04 20:00:00      65.033323  \n",
      "2025-10-04 20:15:00      63.784137  \n",
      "2025-10-04 20:30:00      58.763050  \n",
      "2025-10-04 20:45:00      57.943869  \n",
      "\n",
      "[4527 rows x 24 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │         \u001B[38;5;34m3,072\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │            \u001B[38;5;34m66\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m13,474\u001B[0m (52.63 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,474</span> (52.63 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m13,474\u001B[0m (52.63 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,474</span> (52.63 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.5202 - loss: 0.6985 - val_accuracy: 0.5343 - val_loss: 0.6975\n",
      "Epoch 2/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5461 - loss: 0.6868 - val_accuracy: 0.5245 - val_loss: 0.6951\n",
      "Epoch 3/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5480 - loss: 0.6860 - val_accuracy: 0.5441 - val_loss: 0.6914\n",
      "Epoch 4/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5636 - loss: 0.6816 - val_accuracy: 0.4975 - val_loss: 0.6993\n",
      "Epoch 5/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5663 - loss: 0.6781 - val_accuracy: 0.4926 - val_loss: 0.7008\n",
      "Epoch 6/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5570 - loss: 0.6789 - val_accuracy: 0.5074 - val_loss: 0.6964\n",
      "Epoch 7/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5671 - loss: 0.6733 - val_accuracy: 0.5221 - val_loss: 0.6958\n",
      "Epoch 8/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5758 - loss: 0.6747 - val_accuracy: 0.5196 - val_loss: 0.6998\n",
      "Epoch 9/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5807 - loss: 0.6731 - val_accuracy: 0.5123 - val_loss: 0.6954\n",
      "Epoch 10/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5876 - loss: 0.6671 - val_accuracy: 0.5049 - val_loss: 0.7127\n",
      "Epoch 11/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5867 - loss: 0.6685 - val_accuracy: 0.5196 - val_loss: 0.6992\n",
      "Epoch 12/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5764 - loss: 0.6691 - val_accuracy: 0.4975 - val_loss: 0.7034\n",
      "Epoch 13/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5900 - loss: 0.6671 - val_accuracy: 0.5074 - val_loss: 0.6965\n",
      "Epoch 14/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5919 - loss: 0.6675 - val_accuracy: 0.5221 - val_loss: 0.7027\n",
      "Epoch 15/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5873 - loss: 0.6626 - val_accuracy: 0.5539 - val_loss: 0.7001\n",
      "Epoch 16/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6053 - loss: 0.6575 - val_accuracy: 0.5245 - val_loss: 0.6982\n",
      "Epoch 17/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5897 - loss: 0.6627 - val_accuracy: 0.5245 - val_loss: 0.7082\n",
      "Epoch 18/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5979 - loss: 0.6596 - val_accuracy: 0.5343 - val_loss: 0.7052\n",
      "Epoch 19/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6099 - loss: 0.6517 - val_accuracy: 0.5098 - val_loss: 0.7074\n",
      "Epoch 20/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5977 - loss: 0.6623 - val_accuracy: 0.5049 - val_loss: 0.7077\n",
      "Epoch 21/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6091 - loss: 0.6511 - val_accuracy: 0.5049 - val_loss: 0.7208\n",
      "Epoch 22/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.6039 - loss: 0.6524 - val_accuracy: 0.5392 - val_loss: 0.6934\n",
      "Epoch 23/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6159 - loss: 0.6474 - val_accuracy: 0.5221 - val_loss: 0.7087\n",
      "Epoch 24/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5993 - loss: 0.6525 - val_accuracy: 0.5343 - val_loss: 0.7038\n",
      "Epoch 25/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6113 - loss: 0.6470 - val_accuracy: 0.5098 - val_loss: 0.7156\n",
      "Epoch 26/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6277 - loss: 0.6442 - val_accuracy: 0.5196 - val_loss: 0.7058\n",
      "Epoch 27/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6107 - loss: 0.6448 - val_accuracy: 0.5637 - val_loss: 0.7053\n",
      "Epoch 28/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6320 - loss: 0.6378 - val_accuracy: 0.5735 - val_loss: 0.6995\n",
      "Epoch 29/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6236 - loss: 0.6377 - val_accuracy: 0.5368 - val_loss: 0.7120\n",
      "Epoch 30/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6222 - loss: 0.6361 - val_accuracy: 0.5270 - val_loss: 0.7231\n",
      "Epoch 31/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6203 - loss: 0.6393 - val_accuracy: 0.5392 - val_loss: 0.7361\n",
      "Epoch 32/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6222 - loss: 0.6381 - val_accuracy: 0.5172 - val_loss: 0.7332\n",
      "Epoch 33/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6315 - loss: 0.6348 - val_accuracy: 0.5343 - val_loss: 0.7340\n",
      "Epoch 34/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6446 - loss: 0.6279 - val_accuracy: 0.5564 - val_loss: 0.7127\n",
      "Epoch 35/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6339 - loss: 0.6355 - val_accuracy: 0.5294 - val_loss: 0.7242\n",
      "Epoch 36/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6383 - loss: 0.6311 - val_accuracy: 0.5343 - val_loss: 0.7163\n",
      "Epoch 37/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6337 - loss: 0.6317 - val_accuracy: 0.5319 - val_loss: 0.7162\n",
      "Epoch 38/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6522 - loss: 0.6202 - val_accuracy: 0.5245 - val_loss: 0.7242\n",
      "Epoch 39/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6416 - loss: 0.6230 - val_accuracy: 0.5294 - val_loss: 0.7172\n",
      "Epoch 40/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6380 - loss: 0.6298 - val_accuracy: 0.5294 - val_loss: 0.7458\n",
      "Epoch 41/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6448 - loss: 0.6200 - val_accuracy: 0.5343 - val_loss: 0.7293\n",
      "Epoch 42/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6571 - loss: 0.6152 - val_accuracy: 0.5368 - val_loss: 0.7223\n",
      "Epoch 43/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6492 - loss: 0.6225 - val_accuracy: 0.5466 - val_loss: 0.7094\n",
      "Epoch 44/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6560 - loss: 0.6175 - val_accuracy: 0.5319 - val_loss: 0.7447\n",
      "Epoch 45/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6533 - loss: 0.6151 - val_accuracy: 0.5319 - val_loss: 0.7506\n",
      "Epoch 46/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6558 - loss: 0.6153 - val_accuracy: 0.5392 - val_loss: 0.7378\n",
      "Epoch 47/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6708 - loss: 0.6016 - val_accuracy: 0.5368 - val_loss: 0.7626\n",
      "Epoch 48/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6525 - loss: 0.6164 - val_accuracy: 0.5564 - val_loss: 0.7119\n",
      "Epoch 49/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6645 - loss: 0.6047 - val_accuracy: 0.5368 - val_loss: 0.7360\n",
      "Epoch 50/50\n",
      "\u001B[1m115/115\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6582 - loss: 0.6120 - val_accuracy: 0.5417 - val_loss: 0.7277\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T21:15:18.204079Z",
     "start_time": "2025-10-04T21:15:18.185608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine features, actual, and predictions into one table\n",
    "results_full = x_test.copy()\n",
    "results_full['Actual'] = y_test.values\n",
    "results_full['RandomForest_Pred'] = predictions_rf\n",
    "results_full['XGBoost_Pred'] = predictions_xgb_decoded\n",
    "results_full['NeuralNet_Pred'] = predictions_neural_decoded\n",
    "\n",
    "# Save the full table to CSV\n",
    "results_full.to_csv(\"model_predictions_full.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV file saved as 'model_predictions_full.csv'\")\n"
   ],
   "id": "41d1a950bbbfd1f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file saved as 'model_predictions_full.csv'\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T21:15:18.342686Z",
     "start_time": "2025-10-04T21:15:18.296891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority_vote(row):\n",
    "    preds = [row['RandomForest_Pred'], row['XGBoost_Pred'], row['NeuralNet_Pred']]\n",
    "    most_common = Counter(preds).most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "results_full['Voted_Pred'] = results_full.apply(majority_vote, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_rf = accuracy_score(results_full['Actual'], results_full['RandomForest_Pred'])\n",
    "acc_xgb = accuracy_score(results_full['Actual'], results_full['XGBoost_Pred'])\n",
    "acc_nn = accuracy_score(results_full['Actual'], results_full['NeuralNet_Pred'])\n",
    "acc_vote = accuracy_score(results_full['Actual'], results_full['Voted_Pred'])\n",
    "\n",
    "print(f\"RandomForest Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"XGBoost Accuracy:      {acc_xgb:.4f}\")\n",
    "print(f\"NeuralNet Accuracy:    {acc_nn:.4f}\")\n",
    "print(f\"Voting Accuracy:       {acc_vote:.4f}\")\n",
    "\n",
    "# Agreement among models\n",
    "results_full['Agreement'] = (\n",
    "    (results_full['RandomForest_Pred'] == results_full['XGBoost_Pred']) &\n",
    "    (results_full['XGBoost_Pred'] == results_full['NeuralNet_Pred'])\n",
    ")\n",
    "\n",
    "agreement_rate = results_full['Agreement'].mean()\n",
    "print(f\"Models fully agree on {agreement_rate*100:.2f}% of cases\")\n",
    "\n",
    "# Compare per-model correctness\n",
    "results_full['RF_Correct'] = results_full['RandomForest_Pred'] == results_full['Actual']\n",
    "results_full['XGB_Correct'] = results_full['XGBoost_Pred'] == results_full['Actual']\n",
    "results_full['NN_Correct'] = results_full['NeuralNet_Pred'] == results_full['Actual']\n",
    "results_full['Vote_Correct'] = results_full['Voted_Pred'] == results_full['Actual']\n",
    "\n",
    "\n",
    "results_full.to_csv(\"model_voting_analysis.csv\", index=False)\n",
    "print(\"✅ Saved as 'model_voting_analysis.csv'\")\n",
    "\n",
    "pred_matrix = pd.DataFrame({\n",
    "    'RF': results_full['RandomForest_Pred'],\n",
    "    'XGB': results_full['XGBoost_Pred'],\n",
    "    'NN': results_full['NeuralNet_Pred']\n",
    "})\n",
    "print(\"\\nPrediction Correlation Matrix:\")\n",
    "print(pd.crosstab(pred_matrix['RF'], pred_matrix['XGB'], normalize='index'))\n",
    "\n"
   ],
   "id": "6b4a23673c6dc78f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Accuracy: 0.5210\n",
      "XGBoost Accuracy:      0.5453\n",
      "NeuralNet Accuracy:    0.5188\n",
      "Voting Accuracy:       0.5210\n",
      "Models fully agree on 74.83% of cases\n",
      "✅ Saved as 'model_voting_analysis.csv'\n",
      "\n",
      "Prediction Correlation Matrix:\n",
      "XGB        Buy      Sell\n",
      "RF                      \n",
      "Buy   0.679245  0.320755\n",
      "Sell  0.060519  0.939481\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
