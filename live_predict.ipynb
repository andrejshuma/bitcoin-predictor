{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-13T12:27:27.837672Z"
    }
   },
   "source": [
    "import ccxt\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD\n",
    "from ta.volatility import BollingerBands, AverageTrueRange\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import os\n",
    "import signal\n",
    "\n",
    "# --- Global Flag for Interruption ---\n",
    "stop_signal = False\n",
    "\n",
    "def keyboard_interrupt_handler(signum, frame):\n",
    "    \"\"\"Sets the global flag to True upon catching Ctrl+C.\"\"\"\n",
    "    global stop_signal\n",
    "    stop_signal = True\n",
    "    print(\"\\n\\n!! Ctrl+C detected. Preparing to stop prediction loop. !!\")\n",
    "\n",
    "# Set the signal handler for reliable interrupt detection\n",
    "signal.signal(signal.SIGINT, keyboard_interrupt_handler)\n",
    "\n",
    "\n",
    "# --- Custom Sleep Function ---\n",
    "def interruptible_sleep(seconds):\n",
    "    \"\"\"Sleeps for the given duration but checks for interrupt every second.\"\"\"\n",
    "    global stop_signal\n",
    "    for _ in range(int(seconds)):\n",
    "        if stop_signal:\n",
    "            return True # Interrupted\n",
    "        time.sleep(1)\n",
    "    return stop_signal\n",
    "\n",
    "# Suppress minor warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ----------------------------\n",
    "# Load saved models and preprocessors\n",
    "# ----------------------------\n",
    "try:\n",
    "    forest_model = joblib.load('forest_model.pkl')\n",
    "    xgb_model = joblib.load('xgb_model.pkl')\n",
    "    label_encoder = joblib.load('label_encoder.pkl')\n",
    "    scaler_tabular = joblib.load('scaler_tabular.pkl')\n",
    "    scaler_long = joblib.load('scaler_long.pkl')\n",
    "    neural_model = load_model('neural_model.keras', compile=False)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: One or more model files not found. Please ensure all required files are in the directory. Missing: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------\n",
    "# Define Activity Helpers (DUMMY IMPLEMENTATION)\n",
    "# ----------------------------\n",
    "\n",
    "def buy_col(row):\n",
    "    if 'rsi_6' in row and row['rsi_6'] < 30:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def sell_col(row):\n",
    "    if 'rsi_6' in row and row['rsi_6'] > 70:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def define_activity(row):\n",
    "    if row['buy_index'] > row['sell_index']:\n",
    "        return 'BUY'\n",
    "    elif row['sell_index'] > row['buy_index']:\n",
    "        return 'SELL'\n",
    "    return 'HOLD'\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration and Helper Functions\n",
    "# ----------------------------\n",
    "binance = ccxt.binance()\n",
    "symbol = 'BTC/USDT'\n",
    "timeframe = '15m'\n",
    "limit_historical = 200\n",
    "prediction_interval_sec = 5 * 60 # 5 minutes\n",
    "\n",
    "def get_current_candle_start_ms(tf):\n",
    "    now_ms = int(datetime.now(timezone.utc).timestamp() * 1000)\n",
    "\n",
    "    unit = tf[-1]\n",
    "    value = int(tf[:-1])\n",
    "\n",
    "    if unit == 'm':\n",
    "        interval_ms = value * 60 * 1000\n",
    "    elif unit == 'h':\n",
    "        interval_ms = value * 60 * 60 * 1000\n",
    "    else:\n",
    "        raise ValueError(f\"Timeframe {tf} not supported for calculation.\")\n",
    "\n",
    "    start_ms = now_ms - (now_ms % interval_ms)\n",
    "    return start_ms\n",
    "\n",
    "def clear_console():\n",
    "    if os.name == 'nt':\n",
    "        os.system('cls')\n",
    "    else:\n",
    "        os.system('clear')\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Fetch Historical Context (Closed Candles Only)\n",
    "# ----------------------------\n",
    "since_dt = datetime.now(timezone.utc) - pd.Timedelta(days=7)\n",
    "since = int(since_dt.timestamp() * 1000)\n",
    "\n",
    "all_candles = []\n",
    "clear_console()\n",
    "print(f\"Fetching historical data for {symbol} on {timeframe}...\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        candles = binance.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=limit_historical)\n",
    "        if not candles:\n",
    "            break\n",
    "        all_candles.extend(candles)\n",
    "        since = candles[-1][0] + 1\n",
    "        time.sleep(0.1)\n",
    "        if len(candles) < limit_historical:\n",
    "             break\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching historical data: {e}. Retrying in 5 seconds.\")\n",
    "        time.sleep(5)\n",
    "        break\n",
    "    if stop_signal:\n",
    "        print(\"\\nStopping historical data fetch.\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "historical_df = pd.DataFrame(all_candles, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "historical_df['timestamp'] = pd.to_datetime(historical_df['timestamp'], unit='ms')\n",
    "historical_df = historical_df.tail(limit_historical)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# LIVE PREDICTION LOOP\n",
    "# =========================================================\n",
    "clear_console()\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸš€ Starting Real-Time Prediction for {symbol} / {timeframe}\")\n",
    "print(f\"   Re-predicting every {prediction_interval_sec / 60:.0f} minutes...\")\n",
    "print(\"   Press Ctrl+C to stop.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "while not stop_signal:\n",
    "    try:\n",
    "        clear_console()\n",
    "\n",
    "        # --- 2. Get Live Price and Construct Forming Candle Data ---\n",
    "\n",
    "        last_closed_candle = historical_df.iloc[-1]\n",
    "        ticker = binance.fetch_ticker(symbol)\n",
    "        live_price = ticker['last']\n",
    "        current_candle_start_ms = get_current_candle_start_ms(timeframe)\n",
    "        current_candle_start_dt = pd.to_datetime(current_candle_start_ms, unit='ms')\n",
    "\n",
    "        current_open = last_closed_candle['close']\n",
    "        current_high = max(live_price, current_open)\n",
    "        current_low = min(live_price, current_open)\n",
    "        current_volume = 0\n",
    "\n",
    "        new_row = pd.DataFrame({\n",
    "            'timestamp': [current_candle_start_dt],\n",
    "            'open': [current_open],\n",
    "            'high': [current_high],\n",
    "            'low': [current_low],\n",
    "            'close': [live_price],\n",
    "            'volume': [current_volume]\n",
    "        })\n",
    "\n",
    "        # --- 3. Combine Data and Recalculate Features ---\n",
    "\n",
    "        df = pd.concat([historical_df, new_row]).drop_duplicates(subset=['timestamp'], keep='last').sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Feature engineering\n",
    "        # ----------------------------\n",
    "        df['rsi_6'] = RSIIndicator(df['close'], window=6).rsi()\n",
    "        df['rsi_12'] = RSIIndicator(df['close'], window=12).rsi()\n",
    "\n",
    "        macd_indicator = MACD(close=df['close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "        df['macd'] = macd_indicator.macd()\n",
    "        df['macd_signal'] = macd_indicator.macd_signal()\n",
    "        df['macd_hist'] = macd_indicator.macd_diff()\n",
    "\n",
    "        df['ema_21'] = df['close'].ewm(span=21, adjust=False).mean()\n",
    "        df['sma_50'] = df['close'].rolling(window=50).mean()\n",
    "        df['ema/sma crossover'] = df['ema_21'] - df['sma_50']\n",
    "        df['trends with sma'] = df['close'] / df['sma_50'] - 1\n",
    "\n",
    "        df['price change'] = np.log(df['close'] / df['close'].shift(1))\n",
    "\n",
    "        df['buy_index'] = df.apply(buy_col, axis=1)\n",
    "        df['sell_index'] = df.apply(sell_col, axis=1)\n",
    "        scale = 1\n",
    "        df['signal_scaled'] = 0.5 * (np.tanh((df['buy_index'] - df['sell_index']) / scale) + 1)\n",
    "        df['activity'] = df.apply(define_activity, axis=1)\n",
    "\n",
    "        bollinger = BollingerBands(close=df['close'], window=20, window_dev=2)\n",
    "        df['bollinger_hband'] = bollinger.bollinger_hband()\n",
    "        df['bollinger_lband'] = bollinger.bollinger_lband()\n",
    "        df['bollinger_mavg'] = bollinger.bollinger_mavg()\n",
    "        df['bollinger_bandwidth'] = bollinger.bollinger_wband()\n",
    "\n",
    "        atr = AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14)\n",
    "        df['atr'] = atr.average_true_range()\n",
    "\n",
    "        df['volume_change'] = df['volume'].pct_change()\n",
    "        df['volume_sma_10'] = df['volume'].rolling(window=10).mean()\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        df.set_index('timestamp', inplace=True)\n",
    "\n",
    "        # --- 4. Select features and Predict on the Latest Row ---\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"Dataframe is empty after dropping NaNs. Waiting for more data.\")\n",
    "            interruptible_sleep(prediction_interval_sec)\n",
    "            continue\n",
    "\n",
    "        feature_cols = [c for c in df.columns if c not in ['date', 'next_high', 'next_low', 'buy_index', 'sell_index', 'signal', 'signal_scaled', 'activity']]\n",
    "        X = df[feature_cols]\n",
    "        X_latest = X.iloc[[-1]]\n",
    "\n",
    "        # Scale features\n",
    "        X_tabular_scaled = scaler_tabular.transform(X_latest)\n",
    "        X_long_scaled = scaler_long.transform(X_latest)\n",
    "\n",
    "        # Get individual model predictions and probabilities\n",
    "        proba_rf = forest_model.predict_proba(X_tabular_scaled) # RandomForest probabilities\n",
    "        proba_xgb = xgb_model.predict_proba(X_tabular_scaled)\n",
    "        proba_nn = neural_model.predict(X_long_scaled)\n",
    "\n",
    "        # Get predicted classes\n",
    "        pred_rf = label_encoder.inverse_transform(np.argmax(proba_rf, axis=1))\n",
    "        pred_xgb = label_encoder.inverse_transform(np.argmax(proba_xgb, axis=1))\n",
    "        pred_nn = label_encoder.inverse_transform(np.argmax(proba_nn, axis=1))\n",
    "\n",
    "        # Majority voting\n",
    "        votes = [pred_rf[0], pred_xgb[0], pred_nn[0]]\n",
    "        voted_pred = Counter(votes).most_common(1)[0][0]\n",
    "\n",
    "        class_names = label_encoder.classes_\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # ðŸ”¥ NEW: ENSEMBLE CONFIDENCE CHECK\n",
    "        # ----------------------------------------------------\n",
    "        FINAL_PREDICTION = voted_pred\n",
    "        CONFIDENCE_THRESHOLD = 0.2 # Using 10% from the user input\n",
    "\n",
    "        # Get the average probability for each class across all three models\n",
    "        # Ensure probas are arrays and handle potential 1D output from RF/XGB if applicable (though predict_proba is usually 2D)\n",
    "\n",
    "        # Map class names to column indices for consistent ordering\n",
    "        class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "        # Initialize dictionary to hold summed probabilities\n",
    "        ensemble_probas = {name: 0.0 for name in class_names}\n",
    "\n",
    "        # Sum probabilities from all three models\n",
    "        for name in class_names:\n",
    "            idx = class_indices[name]\n",
    "            ensemble_probas[name] += proba_rf[0][idx]\n",
    "            ensemble_probas[name] += proba_xgb[0][idx]\n",
    "            ensemble_probas[name] += proba_nn[0][idx]\n",
    "            # Average: Divide by the number of models (3)\n",
    "            ensemble_probas[name] /= 3.0\n",
    "\n",
    "        # Convert dictionary to list of (class, average_proba) tuples and sort\n",
    "        sorted_probas = sorted(ensemble_probas.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        # Extract top two average probabilities\n",
    "        top_signal_proba = sorted_probas[0][1]\n",
    "        second_signal_proba = sorted_probas[1][1]\n",
    "\n",
    "        # Check the margin\n",
    "        confidence_margin = top_signal_proba - second_signal_proba\n",
    "\n",
    "        if confidence_margin < CONFIDENCE_THRESHOLD:\n",
    "            FINAL_PREDICTION = 'HOLD'\n",
    "            reasoning = f\"Ensemble Margin ({confidence_margin:.4f}) is below threshold ({CONFIDENCE_THRESHOLD:.4f}). Overridden to HOLD.\"\n",
    "        else:\n",
    "            reasoning = \"Ensemble confidence margin is sufficient.\"\n",
    "\n",
    "        # --- 5. Print Results ---\n",
    "\n",
    "        print(\"=\"*50)\n",
    "        print(f\"PREDICTING for CANDLE: {timeframe} / {symbol}\")\n",
    "        print(f\"  Current UTC Time:  {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"  Candle Start Time: {current_candle_start_dt.strftime('%H:%M:%S')} (Forming)\")\n",
    "        print(f\"  Current Price:   {live_price:.2f} USDT\")\n",
    "        print(\"â€”\"*50)\n",
    "\n",
    "        print(f\"Majority Voted Signal: {voted_pred}\")\n",
    "        print(f\"RandomForest Prediction: {pred_rf[0]}\")\n",
    "        print(f\"XGBoost Prediction:      {pred_xgb[0]}\")\n",
    "        print(f\"NeuralNet Prediction:    {pred_nn[0]}\")\n",
    "\n",
    "        # Print ALL probabilities\n",
    "        print(\"\\nâ€” Individual Model Probabilities â€”\")\n",
    "        for i, name in enumerate(class_names):\n",
    "            print(f\"  {name}: RF={proba_rf[0][i]:.4f} | XGB={proba_xgb[0][i]:.4f} | NN={proba_nn[0][i]:.4f}\")\n",
    "\n",
    "        print(\"\\nâ€” Ensemble Average Probabilities â€”\")\n",
    "        for name, proba in sorted_probas:\n",
    "            print(f\"  {name}: {proba:.4f}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Confidence Margin:     {confidence_margin:.4f} (Required: {CONFIDENCE_THRESHOLD:.4f})\")\n",
    "        print(f\"Decision Reason:       {reasoning}\")\n",
    "        print(f\"ðŸš¨ FINAL TRADING SIGNAL: {FINAL_PREDICTION} ðŸš¨\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # ----------------------------\n",
    "        # 6. Wait for the next prediction interval (Interruptible!)\n",
    "        # ----------------------------\n",
    "        if interruptible_sleep(prediction_interval_sec):\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred in the prediction loop: {e}\")\n",
    "        if interruptible_sleep(prediction_interval_sec * 3):\n",
    "             break\n",
    "\n",
    "print(\"\\nPrediction loop gracefully stopped.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching historical data for BTC/USDT on 15m...\n",
      "============================================================\n",
      "ðŸš€ Starting Real-Time Prediction for BTC/USDT / 15m\n",
      "   Re-predicting every 5 minutes...\n",
      "   Press Ctrl+C to stop.\n",
      "============================================================\n",
      "\u001B[1m1/1\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 73ms/step\n",
      "==================================================\n",
      "PREDICTING for CANDLE: 15m / BTC/USDT\n",
      "  Current UTC Time:  2025-10-13 12:27:33\n",
      "  Candle Start Time: 12:15:00 (Forming)\n",
      "  Current Price:   114262.47 USDT\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "Majority Voted Signal: Sell\n",
      "RandomForest Prediction: Sell\n",
      "XGBoost Prediction:      Sell\n",
      "NeuralNet Prediction:    Sell\n",
      "\n",
      "â€” Individual Model Probabilities â€”\n",
      "  Buy: RF=0.3160 | XGB=0.1648 | NN=0.3678\n",
      "  Sell: RF=0.6840 | XGB=0.8352 | NN=0.6322\n",
      "\n",
      "â€” Ensemble Average Probabilities â€”\n",
      "  Sell: 0.7172\n",
      "  Buy: 0.2828\n",
      "\n",
      "==================================================\n",
      "Confidence Margin:     0.4343 (Required: 0.2000)\n",
      "Decision Reason:       Ensemble confidence margin is sufficient.\n",
      "ðŸš¨ FINAL TRADING SIGNAL: Sell ðŸš¨\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
